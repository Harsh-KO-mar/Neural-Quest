{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RksWtNuHg9Rb"
      },
      "source": [
        "# Neural Quest Assignment-1\n",
        "*  In this assignment, we will build a classifier for MNIST from scratch using just [NumPy](https://numpy.org/)\n",
        "\n",
        "*  [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains images of handwritten digits of size 28x28\n",
        "\n",
        "*  The dataset that you are expected to use for training can be found [here](https://drive.google.com/file/d/1DF-OWSP803x34FrvaJ4XeDm_QZUevu32/view?usp=sharing)\n",
        "\n",
        "*   Our model will have 1 hidden layer, like the one below (not our recommendation to use 256 in the hidden layer though, try various values out)\n",
        "\n",
        "**Feel free to redefine any function signatures below, just make sure the final cell remains the same.**\n",
        "\n",
        "<center>\n",
        "<img src=\"https://user-images.githubusercontent.com/81357954/166119893-4ca347b8-b1a4-40b8-9e0a-2e92b5f164ae.png\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyOAG55siwdI"
      },
      "source": [
        "## Import libraries here\n",
        "NumPy, Matplotlib, ...\n",
        "\n",
        "Also remember to initialize the seed for reproducibility of results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7iVUsRLxjAb9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaLDC4wN0eQs"
      },
      "source": [
        "## Load *Dataset*\n",
        "Load data from the given pickle file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6qOjNSmx0iUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d1c100-3f62-466c-e77f-fbf997461d36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# load the data set\n",
        "with open('/content/drive/MyDrive/train_data.pkl', 'rb') as fuk:\n",
        "    dataset = pickle.load(fuk)\n",
        "\n",
        "X = dataset['X']\n",
        "y = dataset['y']\n",
        "\n",
        "# normalize\n",
        "MMS = MinMaxScaler()\n",
        "X_trans = MMS.fit_transform(X)\n",
        "\n",
        "# Split into X_train, y_train, X_test, y_test\n",
        "# you can use stratified splitting from sklearn library\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X_trans, y, test_size=0.2, random_state=666)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id77Oqc90kTf"
      },
      "outputs": [],
      "source": [
        "# display a 4x4 grid,\n",
        "grid = (4,4)\n",
        "# choose 16 images randomly, display the images as well as corresponding labels\n",
        "indices = np.random.choice(X_tr.shape[0], size=grid[0]*grid[1], replace=False)\n",
        "images = X_tr[indices]\n",
        "labels = y_tr[indices]\n",
        "\n",
        "fig, axes = plt.subplots(grid[0], grid[1], figsize=(8, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(images[i].reshape(28, 28), cmap='gray')\n",
        "    ax.set_axis_off()\n",
        "    ax.set_title(f\"Label : {labels[i]}\")\n",
        "\n",
        "fig.tight_layout\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mG088N5_Rm8"
      },
      "outputs": [],
      "source": [
        "print(X_tr.shape, X_te.shape, y_tr.shape, y_te.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1iBxtjsnlXi"
      },
      "outputs": [],
      "source": [
        "X_tr = X_tr.T\n",
        "y_tr = y_tr.T\n",
        "X_te = X_te.T\n",
        "y_te = y_te.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFYnsPVLmsiW"
      },
      "source": [
        "## Building up parts of our classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAsGtgxUpGh2"
      },
      "source": [
        "**Activation functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Di5Ck47msCQ"
      },
      "outputs": [],
      "source": [
        "def relu(z):\n",
        "    return np.maximum(0,z)\n",
        "\n",
        "def softmax(Z):\n",
        "    A = np.exp(Z) / sum(np.exp(Z))\n",
        "    return A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-q5HJHIocdn"
      },
      "source": [
        "**Notes about the Neural Network**\n",
        "*   Input size is (784,) because 28x28 = 784\n",
        "*   Output size will be 10, each element represeting probability of the image representing that digit\n",
        "*   Size of the hidden layer is a hyperparameter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azTAuS5spFcz"
      },
      "source": [
        "**Initialize the layers weights**\n",
        "\n",
        "Generally, we follow the convention that weights are drawn from a standard normal distribution, while the bias vectors are initialized to zero. But you can try everything out :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38E3_hVPocMm"
      },
      "outputs": [],
      "source": [
        "def init_params(l2):\n",
        "    W1 = np.random.rand(l2,784) -0.5\n",
        "    W2 = np.random.rand(10,l2) - 0.5\n",
        "    b1 = np.zeros((l2,1))\n",
        "    b2 = np.zeros((10,1))\n",
        "    return W1,b1,W2,b2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlX8zy-7pv2n"
      },
      "source": [
        "**Forward Propagation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ8lgrqjjASz"
      },
      "outputs": [],
      "source": [
        "def forward_prop(W1,b1,W2,b2,X):\n",
        "    Z1 = W1.dot(X) + b1\n",
        "    A1 = relu(Z1)\n",
        "    Z2 = W2.dot(Z1) + b2\n",
        "    A2 = softmax(Z2)\n",
        "    return Z1,A1,Z2,A2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asZmbRVvuy5x"
      },
      "source": [
        "**Backward Propagation**\n",
        "\n",
        "\n",
        "You may use stochastic gradient descent or batch gradient descent here. Feel free to use any loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAmrTAlimjUN"
      },
      "outputs": [],
      "source": [
        "def y_data(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y\n",
        "\n",
        "def d_relu(Z):\n",
        "    return Z>0\n",
        "\n",
        "def back_prop(Z1,A1,Z2,A2,W2,X,Y):\n",
        "    y= y_data(Y)\n",
        "    dz2 = A2 - y\n",
        "    dw2 = dz2.dot(A1.T)/Y.size\n",
        "    db2 = np.sum(dz2)/Y.size\n",
        "    dz1 = W2.T.dot(dz2)*d_relu(Z1)\n",
        "    dw1 = dz1.dot(X.T)/Y.size\n",
        "    db1 = np.sum(dz1)/Y.size\n",
        "    return dw1,db1,dw2,db2\n",
        "\n",
        "def update_params(w1,dw1,w2,dw2,b1,db1,b2,db2,a):\n",
        "    w1 = w1 - a*dw1\n",
        "    b1 = b1 - a*db1\n",
        "    w2 = w2 - a*dw2\n",
        "    b2 = b2 - a*db2\n",
        "    return w1,b1,w2,b2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVDz0IGnvzpe"
      },
      "outputs": [],
      "source": [
        "def cost_func(y_pred, y):\n",
        "    epsilon = 1e-8\n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "    loss = -np.mean(y * np.log(y_pred))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUlhpcs9ylOX"
      },
      "source": [
        "\n",
        "## Integrate everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDGdT7PVmjRU"
      },
      "outputs": [],
      "source": [
        "def pred(A2):\n",
        "    return np.argmax(A2,axis=0)\n",
        "\n",
        "def accuracy(predict,y):\n",
        "    return (np.sum(predict==y)/y.size)\n",
        "\n",
        "def train(X,Y,epoch,a,hid_dim):\n",
        "    w1,b1,w2,b2 = init_params(hid_dim)\n",
        "    for i in range(epoch):\n",
        "        z1,a1,z2,a2 = forward_prop(w1,b1,w2,b2,X)\n",
        "        dw1,db1,dw2,db2 = back_prop(z1,a1,z2,a2,w2,X,Y)\n",
        "        w1,b1,w2,b2 = update_params(w1,dw1,w2,dw2,b1,db1,b2,db2,a)\n",
        "        if i%50 ==0:\n",
        "            print(\"Iteration: \",i)\n",
        "            print(\"Loss: \",cost_func(pred(a2),Y.reshape(-1)))\n",
        "    return w1,b1,w2,b2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uunr7uKNRlW",
        "outputId": "cb3e3e47-3e18-4fb6-c7f4-0b8f4dce5493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "Loss:  29.56097121655411\n",
            "Iteration:  50\n",
            "Loss:  1.872769252513908\n",
            "Iteration:  100\n",
            "Loss:  1.3266728215886117\n",
            "Iteration:  150\n",
            "Loss:  1.1175213424218609\n",
            "Iteration:  200\n",
            "Loss:  1.026569231297971\n",
            "Iteration:  250\n",
            "Loss:  0.945594988904972\n",
            "Iteration:  300\n",
            "Loss:  0.8653882748758878\n",
            "Iteration:  350\n",
            "Loss:  0.8504214717795514\n",
            "Iteration:  400\n",
            "Loss:  0.8201041014049215\n",
            "Iteration:  450\n",
            "Loss:  0.7966944863055236\n",
            "Iteration:  500\n",
            "Loss:  0.7775062772076565\n",
            "Iteration:  550\n",
            "Loss:  0.7625394741113203\n",
            "Iteration:  600\n",
            "Loss:  0.7475726710149839\n",
            "Iteration:  650\n",
            "Loss:  0.7364435097382211\n",
            "Iteration:  700\n",
            "Loss:  0.7157202439125248\n",
            "Iteration:  750\n",
            "Loss:  0.7049748468177192\n",
            "Iteration:  800\n",
            "Loss:  0.6999859124522738\n",
            "Iteration:  850\n",
            "Loss:  0.6919268646311696\n",
            "Iteration:  900\n",
            "Loss:  0.6807977033544066\n",
            "Iteration:  950\n",
            "Loss:  0.6723548913513452\n",
            "Iteration:  1000\n",
            "Loss:  0.6681334853498144\n"
          ]
        }
      ],
      "source": [
        "w1,b1,w2,b2 = train(X_tr,y_tr,1001,0.05,256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9XBinWpPmjOS"
      },
      "outputs": [],
      "source": [
        "def predict(X, w1,b1,w2,b2):\n",
        "    _,_,_,a2 = forward_prop(w1,b1,w2,b2,X)\n",
        "    return np.argmax(a2, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CtKSZWw71wc4"
      },
      "outputs": [],
      "source": [
        "def accuracy(predictions, y):\n",
        "    num_correct = np.sum(predictions == y)\n",
        "    accuracy = 100 * num_correct / y.shape[0]\n",
        "    print(f\"Accuracy: {accuracy}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1yMSAythEAew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae2e533-869e-4765-f72e-42ae652a8378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 86.78333333333333%\n"
          ]
        }
      ],
      "source": [
        "prediction=predict(X_te,w1,b1,w2,b2)\n",
        "accuracy(prediction,y_te.reshape(-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGVOZ8yg0VrV"
      },
      "source": [
        "### Save as pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_lvDVwmxmjKX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e226323-5174-4e40-c533-65ee3b4112ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 86.78333333333333%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1c657b86-18ac-466c-8d4a-de21c866c133\", \"model_22B0973.pkl\", 1628574)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pickle\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "roll_num = \"22B0973\" # enter ldap\n",
        "hidden_dim = 256 # replace with your own hidden dimension\n",
        "\n",
        "model_dict = {\n",
        "    'z': hidden_dim, # hidden dimension of your model\n",
        "    'layer_0_wt': w1, # layer 0 weight (784, z)\n",
        "    'layer_0_bias': b1, # layer 0 bias (z, 1)\n",
        "    'layer_1_wt': w2, # layer 1 weight (z, 10)\n",
        "    'layer_1_bias': b2 # layer 1 bias (10, 1)\n",
        "}\n",
        "\n",
        "assert model_dict['layer_0_wt'].shape == (hidden_dim, 784)\n",
        "assert model_dict['layer_0_bias'].shape == (hidden_dim, 1)\n",
        "assert model_dict['layer_1_wt'].shape == (10, hidden_dim)\n",
        "assert model_dict['layer_1_bias'].shape == (10, 1)\n",
        "\n",
        "predictions = predict(X_te,w1,b1,w2,b2 )\n",
        "accuracy(predictions, y_te.reshape(-1))\n",
        "\n",
        "with open(f'model_{roll_num}.pkl', 'wb') as f:\n",
        "    pickle.dump(model_dict, f)\n",
        "    files.download(f'model_{roll_num}.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}